{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8802c716",
   "metadata": {},
   "source": [
    "# Keras Neural Network Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8192b9d",
   "metadata": {},
   "source": [
    "## Jared McMullen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7079a244",
   "metadata": {},
   "source": [
    "### Download TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a089f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp38-cp38-macosx_10_14_x86_64.whl (217.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 217.4 MB 6.1 MB/s eta 0:00:011     |█████████████████████████▌      | 173.5 MB 13.7 MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.20.1-cp38-cp38-macosx_10_9_x86_64.whl (962 kB)\n",
      "\u001b[K     |████████████████████████████████| 962 kB 16.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=9.0.1\n",
      "  Downloading libclang-14.0.1-py2.py3-none-macosx_10_9_x86_64.whl (13.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.2 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.20.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.46.1-cp38-cp38-macosx_10_10_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 7.1 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 14.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 8.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 3.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.25.0-cp38-cp38-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 8.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 9.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 15.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.25.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 7.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 4.4 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2020.12.5)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 12.8 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=57b070a70d08b2ee58b4f76e5a10187aaca360bc08dfcd3bb002845a7386fb0a\n",
      "  Stored in directory: /Users/jaredmcmullen/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.6 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.46.1 importlib-metadata-4.11.3 keras-2.8.0 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.3.7 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.20.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.25.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf0adc7",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3081e378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>50.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>45.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>49.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0    Adelie  Torgersen              39.1             18.7              181.0   \n",
       "1    Adelie  Torgersen              39.5             17.4              186.0   \n",
       "2    Adelie  Torgersen              40.3             18.0              195.0   \n",
       "3    Adelie  Torgersen               NaN              NaN                NaN   \n",
       "4    Adelie  Torgersen              36.7             19.3              193.0   \n",
       "..      ...        ...               ...              ...                ...   \n",
       "339  Gentoo     Biscoe               NaN              NaN                NaN   \n",
       "340  Gentoo     Biscoe              46.8             14.3              215.0   \n",
       "341  Gentoo     Biscoe              50.4             15.7              222.0   \n",
       "342  Gentoo     Biscoe              45.2             14.8              212.0   \n",
       "343  Gentoo     Biscoe              49.9             16.1              213.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "0         3750.0    MALE  \n",
       "1         3800.0  FEMALE  \n",
       "2         3250.0  FEMALE  \n",
       "3            NaN     NaN  \n",
       "4         3450.0  FEMALE  \n",
       "..           ...     ...  \n",
       "339          NaN     NaN  \n",
       "340       4850.0  FEMALE  \n",
       "341       5750.0    MALE  \n",
       "342       5200.0  FEMALE  \n",
       "343       5400.0    MALE  \n",
       "\n",
       "[344 rows x 7 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "mydata = pd.read_csv(\"/Users/jaredmcmullen/Desktop/GSB-S545/data/penguins_size.csv\")\n",
    "mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189d6372",
   "metadata": {},
   "source": [
    "### Drop NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef7609ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>47.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>214.0</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>50.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>45.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>49.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0    Adelie  Torgersen              39.1             18.7              181.0   \n",
       "1    Adelie  Torgersen              39.5             17.4              186.0   \n",
       "2    Adelie  Torgersen              40.3             18.0              195.0   \n",
       "4    Adelie  Torgersen              36.7             19.3              193.0   \n",
       "5    Adelie  Torgersen              39.3             20.6              190.0   \n",
       "..      ...        ...               ...              ...                ...   \n",
       "338  Gentoo     Biscoe              47.2             13.7              214.0   \n",
       "340  Gentoo     Biscoe              46.8             14.3              215.0   \n",
       "341  Gentoo     Biscoe              50.4             15.7              222.0   \n",
       "342  Gentoo     Biscoe              45.2             14.8              212.0   \n",
       "343  Gentoo     Biscoe              49.9             16.1              213.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "0         3750.0    MALE  \n",
       "1         3800.0  FEMALE  \n",
       "2         3250.0  FEMALE  \n",
       "4         3450.0  FEMALE  \n",
       "5         3650.0    MALE  \n",
       "..           ...     ...  \n",
       "338       4925.0  FEMALE  \n",
       "340       4850.0  FEMALE  \n",
       "341       5750.0    MALE  \n",
       "342       5200.0  FEMALE  \n",
       "343       5400.0    MALE  \n",
       "\n",
       "[334 rows x 7 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata = mydata.dropna()\n",
    "mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6fc36d",
   "metadata": {},
   "source": [
    "### Use label encoder to transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "037ede74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-75-ed3f4b6b8fdd>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[label] = LabelEncoder().fit(mydata[label]).transform(mydata[label])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>62</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>26</td>\n",
       "      <td>45</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     species  island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0          0       2                41               56                  5   \n",
       "1          0       2                44               43                 10   \n",
       "2          0       2                50               49                 19   \n",
       "4          0       2                21               62                 17   \n",
       "5          0       2                43               73                 14   \n",
       "..       ...     ...               ...              ...                ...   \n",
       "338        2       0               107                6                 37   \n",
       "340        2       0               104               12                 38   \n",
       "341        2       0               135               26                 45   \n",
       "342        2       0                88               17                 35   \n",
       "343        2       0               130               30                 36   \n",
       "\n",
       "     body_mass_g  sex  \n",
       "0             30    2  \n",
       "1             32    1  \n",
       "2             11    1  \n",
       "4             18    1  \n",
       "5             26    2  \n",
       "..           ...  ...  \n",
       "338           68    1  \n",
       "340           65    1  \n",
       "341           86    2  \n",
       "342           75    1  \n",
       "343           79    2  \n",
       "\n",
       "[334 rows x 7 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Use label encoder to get in the model ingesting format\n",
    "for label in mydata.columns:\n",
    "    mydata[label] = LabelEncoder().fit(mydata[label]).transform(mydata[label])\n",
    "\n",
    "#Set X and Y values for the models\n",
    "mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155ec6ab",
   "metadata": {},
   "source": [
    "### Obtain X/Y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7e24f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = mydata.iloc[:,:1].values\n",
    "X = mydata.iloc[:,1:6].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb773d5",
   "metadata": {},
   "source": [
    "### SCALE/ONE HOT ENCODE/SPLIT X/Y variabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f77cacc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "63a7255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "Y = ohe.fit_transform(Y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0daa07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc29cbe0",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "0aa86812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1758b13",
   "metadata": {},
   "source": [
    "## Recreating Models from previous activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12abd0b",
   "metadata": {},
   "source": [
    "### Model 1 - Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "03423d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=5, activation='sigmoid'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "f43ad39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_53 (Dense)            (None, 100)               600       \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 20)                2020      \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,683\n",
      "Trainable params: 2,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9867\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 0.9867\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9867\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 0.9867\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.9933\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.9900\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0388 - accuracy: 0.9933\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 993us/step - loss: 0.0385 - accuracy: 0.9933\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9933\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9933\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9933\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 998us/step - loss: 0.0370 - accuracy: 0.9900\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9900\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9900\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9900\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9933\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0353 - accuracy: 0.9933\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.0349 - accuracy: 0.9900\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.0347 - accuracy: 0.9900\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 0.9900\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 986us/step - loss: 0.0341 - accuracy: 0.9933\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9933\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0335 - accuracy: 0.9933\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9933\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0331 - accuracy: 0.9933\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9933\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 0.9933\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9933\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9933\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.0320 - accuracy: 0.9933\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.9933\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9933\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0311 - accuracy: 0.9933\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9933\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.9933\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9933\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9933\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9933\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 0.9933\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9933\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9933\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9933\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9933\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9933\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9933\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9933\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 0.9933\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9933\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9933\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 993us/step - loss: 0.0273 - accuracy: 0.9933\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 935us/step - loss: 0.0271 - accuracy: 0.9933\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 969us/step - loss: 0.0269 - accuracy: 0.9933\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.9933\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 0.9933\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9933\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 986us/step - loss: 0.0262 - accuracy: 0.9933\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 991us/step - loss: 0.0258 - accuracy: 0.9933\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 0.9933\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9933\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9933\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 987us/step - loss: 0.0250 - accuracy: 0.9933\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0248 - accuracy: 0.9933\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9967\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9967\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9967\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 954us/step - loss: 0.0240 - accuracy: 0.9967\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 981us/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 973us/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9967\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 992us/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 934us/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 978us/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 956us/step - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 944us/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 934us/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 954us/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 966us/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 968us/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 961us/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 975us/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 979us/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 951us/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 984us/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 957us/step - loss: 0.0185 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72caed53",
   "metadata": {},
   "source": [
    "### Model 2 - Changed Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ac33ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=5, activation='sigmoid'))\n",
    "model.add(Dense(20, activation='sigmoid'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "6411c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_53 (Dense)            (None, 100)               600       \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 20)                2020      \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,683\n",
      "Trainable params: 2,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9733\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9767\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9767\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9767\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.9767\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9767\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9800\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9800\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9800\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9800\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9800\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1037 - accuracy: 0.9800\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.9800\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9800\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0992 - accuracy: 0.9800\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.9800\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9800\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.9800\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9800\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0925 - accuracy: 0.9800\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9800\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9800\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 995us/step - loss: 0.0888 - accuracy: 0.9800\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0876 - accuracy: 0.9800\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0864 - accuracy: 0.9800\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0851 - accuracy: 0.9800\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0841 - accuracy: 0.9800\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9800\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 985us/step - loss: 0.0822 - accuracy: 0.9800\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0815 - accuracy: 0.9800\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0806 - accuracy: 0.9800\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9800\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0790 - accuracy: 0.9800\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0782 - accuracy: 0.9800\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0774 - accuracy: 0.9833\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9800\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.9800\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9833\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9833\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9800\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9833\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9833\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9833\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9833\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9833\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9833\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9833\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0682 - accuracy: 0.9833\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9833\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9833\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 983us/step - loss: 0.0662 - accuracy: 0.9833\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 960us/step - loss: 0.0656 - accuracy: 0.9833\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 978us/step - loss: 0.0649 - accuracy: 0.9833\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 978us/step - loss: 0.0643 - accuracy: 0.9833\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 988us/step - loss: 0.0637 - accuracy: 0.9833\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0630 - accuracy: 0.9833\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9833\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 981us/step - loss: 0.0618 - accuracy: 0.9833\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9833\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9833\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0601 - accuracy: 0.9833\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9833\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0589 - accuracy: 0.9833\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 979us/step - loss: 0.0584 - accuracy: 0.9833\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9833\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 995us/step - loss: 0.0573 - accuracy: 0.9833\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 978us/step - loss: 0.0567 - accuracy: 0.9833\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 0.9833\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9833\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9833\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 996us/step - loss: 0.0546 - accuracy: 0.9833\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 959us/step - loss: 0.0542 - accuracy: 0.9833\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 983us/step - loss: 0.0534 - accuracy: 0.9833\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0529 - accuracy: 0.9833\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9867\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0519 - accuracy: 0.9867\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9867\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9867\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 988us/step - loss: 0.0505 - accuracy: 0.9867\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 976us/step - loss: 0.0499 - accuracy: 0.9867\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 0.9867\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9867\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 965us/step - loss: 0.0486 - accuracy: 0.9867\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0482 - accuracy: 0.9867\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0477 - accuracy: 0.9867\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9867\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 963us/step - loss: 0.0467 - accuracy: 0.9867\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 972us/step - loss: 0.0463 - accuracy: 0.9867\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 0.9867\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9867\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 0.9867\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 987us/step - loss: 0.0447 - accuracy: 0.9867\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 982us/step - loss: 0.0443 - accuracy: 0.9867\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0439 - accuracy: 0.9867\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9867\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 961us/step - loss: 0.0431 - accuracy: 0.9867\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 973us/step - loss: 0.0427 - accuracy: 0.9867\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0422 - accuracy: 0.9867\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 941us/step - loss: 0.0419 - accuracy: 0.9867\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 951us/step - loss: 0.0415 - accuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d638e9a",
   "metadata": {},
   "source": [
    "### Model 3 - Changed Optimizer and Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "12f77785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=5, activation='sigmoid'))\n",
    "model.add(Dense(20, activation='sigmoid'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "80008d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_53 (Dense)            (None, 100)               600       \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 20)                2020      \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,683\n",
      "Trainable params: 2,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 913us/step - loss: 1.0380 - accuracy: 0.4433\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 875us/step - loss: 1.0104 - accuracy: 0.4433\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 852us/step - loss: 0.9878 - accuracy: 0.4767\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9694 - accuracy: 0.5367\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9483 - accuracy: 0.6233\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9276 - accuracy: 0.7700\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9068 - accuracy: 0.8067\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8873 - accuracy: 0.8067\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8676 - accuracy: 0.8067\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8463 - accuracy: 0.8067\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 988us/step - loss: 0.8253 - accuracy: 0.8067\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8030 - accuracy: 0.8067\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7806 - accuracy: 0.8067\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7582 - accuracy: 0.8067\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7365 - accuracy: 0.8067\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.8067\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.8067\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.8067\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.8067\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6295 - accuracy: 0.8067\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6101 - accuracy: 0.8067\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5922 - accuracy: 0.8067\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.8067\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 999us/step - loss: 0.5597 - accuracy: 0.8067\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.8067\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5305 - accuracy: 0.8067\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.8067\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 988us/step - loss: 0.5043 - accuracy: 0.8067\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 981us/step - loss: 0.4917 - accuracy: 0.8067\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.8067\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.4687 - accuracy: 0.8067\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.8067\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.8133\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.8267\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.8267\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4191 - accuracy: 0.8367\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4105 - accuracy: 0.8433\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4016 - accuracy: 0.8467\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.8533\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3855 - accuracy: 0.8700\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8700\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8733\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8767\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3563 - accuracy: 0.8900\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3489 - accuracy: 0.8967\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.9167\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.9167\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 933us/step - loss: 0.3288 - accuracy: 0.9167\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3224 - accuracy: 0.9167\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.9167\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 978us/step - loss: 0.3101 - accuracy: 0.9200\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 974us/step - loss: 0.3041 - accuracy: 0.9233\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2982 - accuracy: 0.9233\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2925 - accuracy: 0.9233\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.9300\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2814 - accuracy: 0.9300\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2763 - accuracy: 0.9300\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2708 - accuracy: 0.9333\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2655 - accuracy: 0.9333\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 995us/step - loss: 0.2601 - accuracy: 0.9367\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 977us/step - loss: 0.2554 - accuracy: 0.9333\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 978us/step - loss: 0.2504 - accuracy: 0.9367\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 959us/step - loss: 0.2457 - accuracy: 0.9367\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 951us/step - loss: 0.2412 - accuracy: 0.9400\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 948us/step - loss: 0.2365 - accuracy: 0.9433\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 985us/step - loss: 0.2320 - accuracy: 0.9433\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 987us/step - loss: 0.2276 - accuracy: 0.9467\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9500\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 987us/step - loss: 0.2191 - accuracy: 0.9533\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 989us/step - loss: 0.2149 - accuracy: 0.9600\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 995us/step - loss: 0.2112 - accuracy: 0.9600\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.9633\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.2030 - accuracy: 0.9633\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 996us/step - loss: 0.1993 - accuracy: 0.9633\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 989us/step - loss: 0.1955 - accuracy: 0.9633\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 983us/step - loss: 0.1922 - accuracy: 0.9600\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9633\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.9600\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 988us/step - loss: 0.1814 - accuracy: 0.9600\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 918us/step - loss: 0.1781 - accuracy: 0.9633\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.9667\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1716 - accuracy: 0.9667\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 907us/step - loss: 0.1686 - accuracy: 0.9667\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 992us/step - loss: 0.1652 - accuracy: 0.9667\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.9667\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1593 - accuracy: 0.9667\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 899us/step - loss: 0.1567 - accuracy: 0.9667\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9667\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9667\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9667\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 913us/step - loss: 0.1459 - accuracy: 0.9667\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1434 - accuracy: 0.9667\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1409 - accuracy: 0.9667\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 958us/step - loss: 0.1384 - accuracy: 0.9700\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 937us/step - loss: 0.1361 - accuracy: 0.9667\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9667\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9733\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 911us/step - loss: 0.1293 - accuracy: 0.9733\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 974us/step - loss: 0.1270 - accuracy: 0.9733\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc692a1",
   "metadata": {},
   "source": [
    "### Model 4 - Changed Optimizer and Layer Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "bd9c67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=5, activation='sigmoid'))\n",
    "model.add(Dense(50, activation='sigmoid'))\n",
    "model.add(Dense(20, activation='sigmoid'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8c7b2925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 300)               1800      \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 50)                15050     \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 20)                1020      \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,933\n",
      "Trainable params: 17,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1037 - accuracy: 0.3667\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 994us/step - loss: 1.0304 - accuracy: 0.4933\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0139 - accuracy: 0.4433\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9908 - accuracy: 0.6033\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9550 - accuracy: 0.5667\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9092 - accuracy: 0.7933\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8476 - accuracy: 0.8067\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7769 - accuracy: 0.8067\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.8067\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6281 - accuracy: 0.8067\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.8067\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.8067\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.8067\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.8067\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.8067\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8067\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8100\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4015 - accuracy: 0.8267\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3833 - accuracy: 0.8500\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8700\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8767\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.9233\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3117 - accuracy: 0.9267\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2945 - accuracy: 0.9233\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2767 - accuracy: 0.9500\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2580 - accuracy: 0.9433\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2412 - accuracy: 0.9567\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.9600\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.9633\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.9633\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.9700\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9733\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1628 - accuracy: 0.9767\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1501 - accuracy: 0.9733\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1421 - accuracy: 0.9800\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9800\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9800\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.9833\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9800\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9900\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0975 - accuracy: 0.9900\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9833\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9900\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9900\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0800 - accuracy: 0.9900\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 0.9933\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0717 - accuracy: 0.9933\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9967\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0649 - accuracy: 0.9967\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0620 - accuracy: 0.9967\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9967\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0574 - accuracy: 0.9967\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9967\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9933\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0436 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9933\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 0.9967\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814f287e",
   "metadata": {},
   "source": [
    "### Model 5 - Changed Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "36042a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=5, activation='tanh'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(3, activation='tanh'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "f3fb6eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_69 (Dense)            (None, 300)               1800      \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 50)                15050     \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 20)                1020      \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,933\n",
      "Trainable params: 17,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 9.8321 - accuracy: 0.0433\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.7721 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.6552 - accuracy: 0.0267\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4911 - accuracy: 0.1200\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5605 - accuracy: 0.2300\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3514 - accuracy: 0.2900\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8666 - accuracy: 0.3067\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6135 - accuracy: 0.3067\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.8267 - accuracy: 0.3067\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.0416 - accuracy: 0.3067\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.0954 - accuracy: 0.3067\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2565 - accuracy: 0.3067\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421d7c3",
   "metadata": {},
   "source": [
    "# Exploration of Keras - Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff9676b",
   "metadata": {},
   "source": [
    "### New Setting - Loss Function (also Binary accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "269a3a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=5, activation='tanh'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(3, activation='tanh'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer='adam', metrics=[\"binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "99c1f532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_89 (Dense)            (None, 300)               1800      \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 50)                15050     \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 20)                1020      \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,933\n",
      "Trainable params: 17,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5311 - binary_accuracy: 0.8511\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4056 - binary_accuracy: 0.9778\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3723 - binary_accuracy: 0.9856\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3536 - binary_accuracy: 0.9878\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3444 - binary_accuracy: 0.9900\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3391 - binary_accuracy: 0.9911\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3358 - binary_accuracy: 0.9911\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3334 - binary_accuracy: 0.9922\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3318 - binary_accuracy: 0.9911\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3300 - binary_accuracy: 0.9911\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3288 - binary_accuracy: 0.9911\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3281 - binary_accuracy: 0.9911\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3270 - binary_accuracy: 0.9911\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3258 - binary_accuracy: 0.9922\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3247 - binary_accuracy: 0.9933\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3242 - binary_accuracy: 0.9944\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3232 - binary_accuracy: 0.9956\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3227 - binary_accuracy: 0.9944\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3220 - binary_accuracy: 0.9944\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3217 - binary_accuracy: 0.9944\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3212 - binary_accuracy: 0.9933\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3211 - binary_accuracy: 0.9944\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3211 - binary_accuracy: 0.9944\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3196 - binary_accuracy: 0.9956\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3200 - binary_accuracy: 0.9944\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3206 - binary_accuracy: 0.9922\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3188 - binary_accuracy: 0.9967\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3185 - binary_accuracy: 0.9956\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3180 - binary_accuracy: 0.9956\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3179 - binary_accuracy: 0.9956\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3176 - binary_accuracy: 0.9956\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3172 - binary_accuracy: 0.9956\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3170 - binary_accuracy: 0.9956\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3168 - binary_accuracy: 0.9956\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3167 - binary_accuracy: 0.9989\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3165 - binary_accuracy: 0.9967\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3162 - binary_accuracy: 0.9978\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3161 - binary_accuracy: 0.9989\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3160 - binary_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3159 - binary_accuracy: 0.9967\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3157 - binary_accuracy: 0.9989\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3156 - binary_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3155 - binary_accuracy: 0.9978\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3154 - binary_accuracy: 0.9989\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3153 - binary_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3152 - binary_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3152 - binary_accuracy: 0.9989\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3150 - binary_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3150 - binary_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3151 - binary_accuracy: 0.9989\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3152 - binary_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3147 - binary_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3148 - binary_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3147 - binary_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3146 - binary_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3145 - binary_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3144 - binary_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3144 - binary_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3143 - binary_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3143 - binary_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3143 - binary_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3143 - binary_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3142 - binary_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3142 - binary_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3141 - binary_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3142 - binary_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3141 - binary_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3141 - binary_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3140 - binary_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3140 - binary_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3140 - binary_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3140 - binary_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3140 - binary_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3139 - binary_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3139 - binary_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3139 - binary_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3139 - binary_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3139 - binary_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3139 - binary_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3138 - binary_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3138 - binary_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3138 - binary_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3138 - binary_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3138 - binary_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3138 - binary_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3138 - binary_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3138 - binary_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3137 - binary_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3137 - binary_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3137 - binary_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3137 - binary_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3137 - binary_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3137 - binary_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3137 - binary_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3137 - binary_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3136 - binary_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3136 - binary_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3136 - binary_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3136 - binary_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3136 - binary_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Summary output\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc72ed08",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f1cdf4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.77      0.67        13\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.36      0.29      0.32        34\n",
      "   macro avg       0.20      0.26      0.22        34\n",
      "weighted avg       0.22      0.29      0.25        34\n",
      " samples avg       0.29      0.29      0.29        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Predictions\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = (predictions > 0.5)\n",
    "\n",
    "#Print the confusion matrix\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a8d90",
   "metadata": {},
   "source": [
    "We can learn from the binary cross entropy loss performs best on y labels that are either 1 or 0 and not for multiclass. While the model is able to be ran, it will yield misleading results and only take into account the first two classifications for species."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e260050b",
   "metadata": {},
   "source": [
    "### New Setting - Metrics (top_k accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "6ae790da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=5, activation='tanh'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(3, activation='tanh'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=\"top_k_categorical_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "e5f372cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_145 (Dense)           (None, 300)               1800      \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 50)                15050     \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 20)                1020      \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,933\n",
      "Trainable params: 17,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4360 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.3955 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9789 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0806 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9613 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8366 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7988 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8973 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9656 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5718 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2635 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.9788 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.8932 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.9440 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.1594 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.3202 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9105 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.0180 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.1791 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.2328 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.2865 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.3402 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.3939 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.3939 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.4476 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.5013 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.5550 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.6624 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.7161 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.7161 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.7160 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.7160 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.8234 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.8234 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.9845 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.0382 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.1994 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2531 - top_k_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Summary output\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985c628",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "e0668a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd502455ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.45      1.00      0.62        10\n",
      "           2       0.91      0.91      0.91        11\n",
      "\n",
      "   micro avg       0.45      0.59      0.51        34\n",
      "   macro avg       0.45      0.64      0.51        34\n",
      "weighted avg       0.43      0.59      0.48        34\n",
      " samples avg       0.44      0.59      0.49        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Predictions\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = (predictions > 0.5)\n",
    "\n",
    "#Print the confusion matrix\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d957617c",
   "metadata": {},
   "source": [
    "We can see from changing the metric for accuracy when using the top-k approach is very skewed, as it will use the top accuracy of all of the classification classes, not leading to a very comprehensive result, but still prpvides a baseleine for how the best class if performing. This value will likely always be higher than accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09d4793",
   "metadata": {},
   "source": [
    "### New Setting - Optimizer insert for learning rate (categorical_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "5c257c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=5, activation='tanh'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(3, activation='tanh'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=\"categorical_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "b50efeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_149 (Dense)           (None, 300)               1800      \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 50)                15050     \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 20)                1020      \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,933\n",
      "Trainable params: 17,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2269 - categorical_accuracy: 0.3533\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.8726 - categorical_accuracy: 0.1267\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.3972 - categorical_accuracy: 0.1800\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.6738 - categorical_accuracy: 0.3567\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.2823 - categorical_accuracy: 0.3967\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.1569 - categorical_accuracy: 0.4633\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.7416 - categorical_accuracy: 0.5133\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.3748 - categorical_accuracy: 0.6367\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.2625 - categorical_accuracy: 0.7133\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.0904 - categorical_accuracy: 0.6800\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.1362 - categorical_accuracy: 0.6500\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9269 - categorical_accuracy: 0.6500\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9189 - categorical_accuracy: 0.6500\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9145 - categorical_accuracy: 0.6533\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9661 - categorical_accuracy: 0.6533\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9657 - categorical_accuracy: 0.6533\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9112 - categorical_accuracy: 0.6533\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9106 - categorical_accuracy: 0.6533\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9104 - categorical_accuracy: 0.6533\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9102 - categorical_accuracy: 0.6533\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9101 - categorical_accuracy: 0.6533\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9103 - categorical_accuracy: 0.6533\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9103 - categorical_accuracy: 0.6533\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9643 - categorical_accuracy: 0.6533\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9104 - categorical_accuracy: 0.6533\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 5.9101 - categorical_accuracy: 0.6533\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9103 - categorical_accuracy: 0.6533\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.0182 - categorical_accuracy: 0.6533\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.0179 - categorical_accuracy: 0.6533\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.0177 - categorical_accuracy: 0.6533\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9101 - categorical_accuracy: 0.6533\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9101 - categorical_accuracy: 0.6533\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9100 - categorical_accuracy: 0.6533\n"
     ]
    }
   ],
   "source": [
    "# Summary output\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f8ce53",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "6f189929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.87        13\n",
      "           1       0.13      0.20      0.16        10\n",
      "           2       0.73      1.00      0.85        11\n",
      "\n",
      "   micro avg       0.55      0.76      0.64        34\n",
      "   macro avg       0.54      0.73      0.62        34\n",
      "weighted avg       0.57      0.76      0.65        34\n",
      " samples avg       0.54      0.76      0.62        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaredmcmullen/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Predictions\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = (predictions > 0.5)\n",
    "\n",
    "#Print the confusion matrix\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef9d2b",
   "metadata": {},
   "source": [
    "From the change in optimizer, we can see that the learning rate really affects the accuracy score just over 10 iterations of accuracy scores. This is not what we want with a neural network. We want the accuracy to greatly increase over many epochs. So in this case, using the baseline optimier will yield better results than including a learning rate. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
